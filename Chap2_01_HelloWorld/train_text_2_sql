from typing import Dict, Any
from datasets import load_dataset, concatenate_datasets
import evaluate
import gc
import torch

from transformers import AutoTokenizer
from transformers import AutoModelForSeq2SeqLM
from transformers import DataCollatorForSeq2Seq
from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer

dataset = load_dataset("wikisql")
tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")
table_prefix = "table:"
question_prefix = "question:"

def preprocess_function(examples: Dict[str, Any]):
    """preprocess each row of wikisql datasets by create input with this format
        {question_prefix} {natural_question} {table_prefix} {table_schema}
        the labels will be the SQL statement
        
    Args:
        examples (Dict[str, Any]): each row of datasets
        
    Returns:
        output from tokenizer
    """
    columns_merge = [",".join(table["header"]) for table in examples["table"]]
    question_list = [question.replace(u'\xa0', u' ') for question in examples["question"]]
    assert len(columns_merge) == len(question_list)
    inputs = [f"{question_prefix} {question_list[i]} {table_prefix} {columns_merge[i]}" for i in range(len(columns_merge))]
    targets = [sql["human_readable"] for sql in examples["sql"]]
    model_inputs = tokenizer(inputs, text_target=targets, max_length=512, truncation=True)
    return model_inputs

train_dataset = dataset["train"].map(preprocess_function, batched=True, remove_columns=["phase", "question", "table", "sql"])
test_dataset = dataset["test"].map(preprocess_function, batched=True, remove_columns=["phase", "question", "table", "sql"])
val_dataset = dataset["validation"].map(preprocess_function, batched=True, remove_columns=["phase", "question", "table", "sql"])


# declare model
model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
model = model.cuda()

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)


data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)


# declare training arguments
training_args = Seq2SeqTrainingArguments(
    output_dir="./results",
    evaluation_strategy="steps",
    eval_steps=1000,
    logging_steps=1000,
    save_strategy="steps",
    save_steps=1000,
    learning_rate=5e-6,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    gradient_accumulation_steps=4,
    # gradient_checkpointing=True,
    warmup_ratio=0.01,
    weight_decay=0.01,
    save_total_limit=2,
    num_train_epochs=10,
    fp16=True,
    predict_with_generate=True,
    # generation_max_length=512,
    # generation_num_beams=None,
    lr_scheduler_type="cosine",
    # dataloader_num_workers=2,
    greater_is_better=False,
    metric_for_best_model="eval_loss",
)


# declare trainer
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
    # compute_metrics=compute_metrics,
) # you can evaluate by using compute_metrics function above, but I comment out for the faster training loop

trainer.train()

torch.cuda.empty_cache()
del variables
gc.collect()


from typing import List

table_prefix = "table:"
question_prefix = "question:"

def prepare_input(question: str, table: List[str]):
    print("question:", question)
    print("table:", table)
    join_table = ",".join(table)
    inputs = f"{question_prefix} {question} {table_prefix} {join_table}"
    input_ids = tokenizer(inputs, max_length=700, return_tensors="pt").input_ids
    return input_ids

def inference(question: str, table: List[str]) -> str:
    input_data = prepare_input(question=question, table=table)
    input_data = input_data.to(model.device)
    outputs = model.generate(inputs=input_data, num_beams=10, top_k=10, max_length=512)
    result = tokenizer.decode(token_ids=outputs[0], skip_special_tokens=True)
    return result


test_id = 1000
print("model result:", inference(dataset["test"][test_id]["question"], dataset["test"][test_id]["table"]["header"]))
print("real result:", dataset["test"][test_id]["sql"]["human_readable"])